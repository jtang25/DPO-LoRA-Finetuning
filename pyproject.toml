[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "dpo-project"
version = "0.1.0"
description = "Direct Preference Optimization with LoRA adapters"
readme = "README.md"
requires-python = ">=3.10"
keywords = ["dpo", "rlhf", "lora", "llm"]
authors = [{ name = "Jason" }]

dependencies = [
  "torch",
  "transformers>=4.37.0",
  "datasets>=2.16.0",
  "tqdm",
  "openai>=1.0.0",
  "python-dotenv",
  "matplotlib",
]

[project.optional-dependencies]
dev = ["ruff", "pytest"]

[project.scripts]
dpo-train = "dpo_project.cli.train:main"
dpo-eval-llm = "dpo_project.cli.eval_llm_judge:main"
dpo-plot = "dpo_project.cli.plot_training:main"

[tool.setuptools.packages.find]
where = ["src"]

